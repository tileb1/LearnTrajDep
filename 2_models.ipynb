{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from progress.bar import Bar\n",
    "import pandas as pd\n",
    "\n",
    "from utils import loss_funcs, utils as utils\n",
    "from utils.opt import Options\n",
    "from utils.h36motion3d import H36motion3D\n",
    "import utils.model as nnmodel\n",
    "import utils.data_utils as data_utils\n",
    "from utils.constants import *\n",
    "from utils.model import TimeAutoencoder\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataset\n",
    "acts = data_utils.define_actions('all')\n",
    "test_data = dict()\n",
    "for act in acts:\n",
    "    test_dataset = H36motion3D(path_to_data=opt.data_dir, actions=act, input_n=input_n, output_n=output_n, split=1,\n",
    "                               sample_rate=sample_rate, dct_used=dct_n)\n",
    "    test_data[act] = DataLoader(\n",
    "        dataset=test_dataset,\n",
    "        batch_size=opt.test_batch,\n",
    "        shuffle=False)\n",
    "\n",
    "# Load dummy train dataset for accessing dim_used\n",
    "train_dataset = H36motion3D(path_to_data='./h3.6m/dataset', actions='all', input_n=input_n, output_n=output_n,\n",
    "                          split=0, sample_rate=2, subset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Options()\n",
    "opt._initial()\n",
    "\n",
    "class MyOpt:\n",
    "    def __init__(self):\n",
    "        self.output_n = opt.parser.get_default('output_n')\n",
    "        self.input_n = opt.parser.get_default('input_n')\n",
    "        self.dct_n = opt.parser.get_default('dct_n')\n",
    "        self.linear_size = opt.parser.get_default('linear_size')\n",
    "        self.num_stage = opt.parser.get_default('num_stage')\n",
    "        self.dropout = opt.parser.get_default('dropout') \n",
    "        self.data_dir = opt.parser.get_default('data_dir') \n",
    "        self.sample_rate = opt.parser.get_default('sample_rate')\n",
    "        self.test_batch = opt.parser.get_default('test_batch')\n",
    "        \n",
    "        self.job = opt.parser.get_default('job')\n",
    "        self.test_batch = opt.parser.get_default('test_batch')\n",
    "        self.test_batch = opt.parser.get_default('test_batch')\n",
    "        self.test_batch = opt.parser.get_default('test_batch')\n",
    "        \n",
    "        \n",
    "opt = MyOpt()\n",
    "dct_n = opt.dct_n\n",
    "input_n = opt.input_n\n",
    "output_n = opt.output_n\n",
    "sample_rate = opt.sample_rate\n",
    "\n",
    "time_autoencoder1 = TimeAutoencoder(opt.input_n + opt.output_n, dct_n)\n",
    "extension = 'RAW'\n",
    "name1 = 'autoencoder_' + str(opt.input_n + opt.output_n) + '_' + str(opt.dct_n) + '_' + extension + '.pt'\n",
    "utils.load_model(time_autoencoder1, name1)\n",
    "\n",
    "time_autoencoder2 = TimeAutoencoder(opt.input_n + opt.output_n, dct_n)\n",
    "extension = 'SUBSAMPLED'\n",
    "name2 = 'autoencoder_' + str(opt.input_n + opt.output_n) + '_' + str(opt.dct_n) + '_' + extension + '.pt'\n",
    "utils.load_model(time_autoencoder2, name2)\n",
    "\n",
    "model = nnmodel.MultipleGCN(dct_n, opt.linear_size, opt.dropout, time_autoencoder1, time_autoencoder2, opt,\n",
    "                    num_stage=opt.num_stage, node_n=66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_state_dict = torch.load('/home/tim/Bureau/checkpoint/ckpt_main_3d_3D_in10_out25_dct_n_30_best.pth.tar', map_location=torch.device('cpu'))['state_dict']\n",
    "GCN2_state_dict = torch.load('checkpoint/test/ckpt_main_3d_3D_in10_out25_dct_n_30_best.pth.tar', map_location=torch.device('cpu'))['state_dict']\n",
    "autoencoder1_state_dict = torch.load('/home/tim/Bureau/checkpoint/autoencoder_35_30_MSE30SELU.pt', map_location=torch.device('cpu'))\n",
    "\n",
    "# Overwrite GCN1\n",
    "for key_p1, key_p2 in zip(list(best_state_dict.keys()), [i for i in GCN2_state_dict.keys() if i.startswith('GCN1')]):\n",
    "    assert(key_p1 == '.'.join(key_p2.split('.')[1:]))\n",
    "    GCN2_state_dict[key_p2] = best_state_dict[key_p1]\n",
    "    \n",
    "# Overwrite autoencoder1\n",
    "for key_p1, key_p2 in zip(list(autoencoder1_state_dict.keys()), [i for i in GCN2_state_dict.keys() if i.startswith('autoencoder1')]):\n",
    "    assert(key_p1 == '.'.join(key_p2.split('.')[1:]))\n",
    "    GCN2_state_dict[key_p2] = autoencoder1_state_dict[key_p1]\n",
    "    \n",
    "model.load_state_dict(GCN2_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_3d import my_evaluate\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time index 34\n",
      "1.0 70.81928825378418\n",
      "0.9888888888888889 70.6920919418335\n",
      "0.9777777777777777 70.59364986419678\n",
      "0.9666666666666667 70.52267932891846\n",
      "0.9555555555555556 70.47798538208008\n",
      "0.9444444444444444 70.45895195007324\n",
      "0.9333333333333333 70.46553134918213\n",
      "0.9222222222222223 70.49807739257812\n",
      "0.9111111111111111 70.55760955810547\n",
      "0.9 70.64510726928711\n",
      "Best alpha: 0.9444444444444444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_alpha_vec = torch.zeros(1, 1, 35).float()\n",
    "\n",
    "for time_index in range(34, 35):\n",
    "    print(\"Time index {}\".format(time_index))\n",
    "    best_alpha, min_err = 0, 1e9\n",
    "    for a in reversed(np.linspace(0.9, 1, 10)):\n",
    "        start = time.time()\n",
    "        tmp = 0\n",
    "        for act in ['walking', 'eating', 'smoking', 'discussion']:\n",
    "#             err_3d = my_evaluate(test_data[act], model, train_dataset.dim_used, opt, alpha=a, j=24, dim=time_index)\n",
    "            test_l, test_3d = test(test_data[act], model, input_n=input_n, output_n=output_n, is_cuda=is_cuda,\n",
    "                                   dim_used=train_dataset.dim_used, dct_n=dct_n)\n",
    "            tmp += err_3d\n",
    "        avg = tmp / len(['walking', 'eating', 'smoking', 'discussion'])\n",
    "        print(a, avg)\n",
    "        if avg < min_err:\n",
    "            min_err = avg\n",
    "            best_alpha = a\n",
    "#         print('Time taken: {}'.format(time.time()-start))\n",
    "    print('Best alpha: {}'.format(best_alpha))\n",
    "#     best_alpha_vec[time_index] = best_alpha\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maowei",
   "language": "python",
   "name": "maowei"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
