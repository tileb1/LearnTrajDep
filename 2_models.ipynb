{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from progress.bar import Bar\n",
    "import pandas as pd\n",
    "\n",
    "from utils import loss_funcs, utils as utils\n",
    "from utils.opt import Options\n",
    "from utils.h36motion3d import H36motion3D\n",
    "import utils.model as nnmodel\n",
    "import utils.data_utils as data_utils\n",
    "from utils.constants import *\n",
    "from utils.model import TimeAutoencoder\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Options()\n",
    "opt._initial()\n",
    "\n",
    "class MyOpt:\n",
    "    def __init__(self):\n",
    "        self.output_n = opt.parser.get_default('output_n')\n",
    "        self.input_n = opt.parser.get_default('input_n')\n",
    "        self.dct_n = opt.parser.get_default('dct_n')\n",
    "        self.linear_size = opt.parser.get_default('linear_size')\n",
    "        self.num_stage = opt.parser.get_default('num_stage')\n",
    "        self.dropout = opt.parser.get_default('dropout') \n",
    "        self.data_dir = opt.parser.get_default('data_dir') \n",
    "        self.sample_rate = opt.parser.get_default('sample_rate')\n",
    "        self.test_batch = opt.parser.get_default('test_batch')\n",
    "        \n",
    "        self.job = opt.parser.get_default('job')\n",
    "        self.test_batch = opt.parser.get_default('test_batch')\n",
    "        self.test_batch = opt.parser.get_default('test_batch')\n",
    "        self.test_batch = opt.parser.get_default('test_batch')\n",
    "        \n",
    "        \n",
    "opt = MyOpt()\n",
    "dct_n = opt.dct_n\n",
    "input_n = opt.input_n\n",
    "output_n = opt.output_n\n",
    "sample_rate = opt.sample_rate\n",
    "\n",
    "time_autoencoder1 = TimeAutoencoder(opt.input_n + opt.output_n, dct_n)\n",
    "extension = 'RAW'\n",
    "name1 = 'autoencoder_' + str(opt.input_n + opt.output_n) + '_' + str(opt.dct_n) + '_' + extension + '.pt'\n",
    "utils.load_model(time_autoencoder1, name1)\n",
    "\n",
    "time_autoencoder2 = TimeAutoencoder(opt.input_n + opt.output_n, dct_n)\n",
    "extension = 'SUBSAMPLED'\n",
    "name2 = 'autoencoder_' + str(opt.input_n + opt.output_n) + '_' + str(opt.dct_n) + '_' + extension + '.pt'\n",
    "utils.load_model(time_autoencoder2, name2)\n",
    "\n",
    "model = nnmodel.MultipleGCN(dct_n, opt.linear_size, opt.dropout, time_autoencoder1, time_autoencoder2, opt,\n",
    "                    num_stage=opt.num_stage, node_n=66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading subject 5, action walking, subaction 1\n",
      "Reading subject 5, action walking, subaction 2\n",
      "Reading subject 5, action eating, subaction 1\n",
      "Reading subject 5, action eating, subaction 2\n",
      "Reading subject 5, action smoking, subaction 1\n",
      "Reading subject 5, action smoking, subaction 2\n",
      "Reading subject 5, action discussion, subaction 1\n",
      "Reading subject 5, action discussion, subaction 2\n",
      "Reading subject 5, action directions, subaction 1\n",
      "Reading subject 5, action directions, subaction 2\n",
      "Reading subject 5, action greeting, subaction 1\n",
      "Reading subject 5, action greeting, subaction 2\n",
      "Reading subject 5, action phoning, subaction 1\n",
      "Reading subject 5, action phoning, subaction 2\n",
      "Reading subject 5, action posing, subaction 1\n",
      "Reading subject 5, action posing, subaction 2\n",
      "Reading subject 5, action purchases, subaction 1\n",
      "Reading subject 5, action purchases, subaction 2\n",
      "Reading subject 5, action sitting, subaction 1\n",
      "Reading subject 5, action sitting, subaction 2\n",
      "Reading subject 5, action sittingdown, subaction 1\n",
      "Reading subject 5, action sittingdown, subaction 2\n",
      "Reading subject 5, action takingphoto, subaction 1\n",
      "Reading subject 5, action takingphoto, subaction 2\n",
      "Reading subject 5, action waiting, subaction 1\n",
      "Reading subject 5, action waiting, subaction 2\n",
      "Reading subject 5, action walkingdog, subaction 1\n",
      "Reading subject 5, action walkingdog, subaction 2\n",
      "Reading subject 5, action walkingtogether, subaction 1\n",
      "Reading subject 5, action walkingtogether, subaction 2\n",
      "Reading subject 1, action walking, subaction 1\n",
      "Reading subject 1, action walking, subaction 2\n"
     ]
    }
   ],
   "source": [
    "# Load test dataset\n",
    "acts = data_utils.define_actions('all')\n",
    "test_data = dict()\n",
    "for act in acts:\n",
    "    test_dataset = H36motion3D(path_to_data=opt.data_dir, actions=act, input_n=input_n, output_n=output_n, split=1,\n",
    "                               sample_rate=sample_rate, dct_used=dct_n)\n",
    "    test_data[act] = DataLoader(\n",
    "        dataset=test_dataset,\n",
    "        batch_size=opt.test_batch,\n",
    "        shuffle=False)\n",
    "\n",
    "# Load dummy train dataset for accessing dim_used\n",
    "train_dataset = H36motion3D(path_to_data='./h3.6m/dataset', actions='all', input_n=input_n, output_n=output_n,\n",
    "                          split=0, sample_rate=2, subset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_state_dict = torch.load('/home/tim/Bureau/checkpoint/ckpt_main_3d_3D_in10_out25_dct_n_30_best.pth.tar', map_location=torch.device('cpu'))['state_dict']\n",
    "GCN2_state_dict = torch.load('checkpoint/test/ckpt_main_3d_3D_in10_out25_dct_n_30_best.pth.tar', map_location=torch.device('cpu'))['state_dict']\n",
    "autoencoder1_state_dict = torch.load('/home/tim/Bureau/checkpoint/autoencoder_35_30_MSE30SELU.pt', map_location=torch.device('cpu'))\n",
    "\n",
    "# Overwrite GCN1\n",
    "for key_p1, key_p2 in zip(list(best_state_dict.keys()), [i for i in GCN2_state_dict.keys() if i.startswith('GCN1')]):\n",
    "    assert(key_p1 == '.'.join(key_p2.split('.')[1:]))\n",
    "    GCN2_state_dict[key_p2] = best_state_dict[key_p1]\n",
    "    \n",
    "# Overwrite autoencoder1\n",
    "for key_p1, key_p2 in zip(list(autoencoder1_state_dict.keys()), [i for i in GCN2_state_dict.keys() if i.startswith('autoencoder1')]):\n",
    "    assert(key_p1 == '.'.join(key_p2.split('.')[1:]))\n",
    "    GCN2_state_dict[key_p2] = autoencoder1_state_dict[key_p1]\n",
    "    \n",
    "model.load_state_dict(GCN2_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_3d import my_evaluate\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time index 34\n",
      "1.0 70.81928825378418\n",
      "0.9888888888888889 70.6920919418335\n",
      "0.9777777777777777 70.59364986419678\n",
      "0.9666666666666667 70.52267932891846\n",
      "0.9555555555555556 70.47798538208008\n",
      "0.9444444444444444 70.45895195007324\n",
      "0.9333333333333333 70.46553134918213\n",
      "0.9222222222222223 70.49807739257812\n",
      "0.9111111111111111 70.55760955810547\n",
      "0.9 70.64510726928711\n",
      "Best alpha: 0.9444444444444444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_alpha_vec = torch.zeros(1, 1, 35).float()\n",
    "\n",
    "for time_index in range(34, 35):\n",
    "    print(\"Time index {}\".format(time_index))\n",
    "    best_alpha, min_err = 0, 1e9\n",
    "    for a in reversed(np.linspace(0.9, 1, 10)):\n",
    "        start = time.time()\n",
    "        tmp = 0\n",
    "        for act in ['walking', 'eating', 'smoking', 'discussion']:\n",
    "            err_3d = my_evaluate(test_data[act], model, train_dataset.dim_used, opt, alpha=a, j=24, dim=time_index)\n",
    "            tmp += err_3d\n",
    "        avg = tmp / len(['walking', 'eating', 'smoking', 'discussion'])\n",
    "        print(a, avg)\n",
    "        if avg < min_err:\n",
    "            min_err = avg\n",
    "            best_alpha = a\n",
    "#         print('Time taken: {}'.format(time.time()-start))\n",
    "    print('Best alpha: {}'.format(best_alpha))\n",
    "#     best_alpha_vec[time_index] = best_alpha\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 66, 35])\n",
      "torch.Size([8, 66, 35])\n",
      "torch.Size([8, 66, 35])\n",
      "torch.Size([8, 66, 35])\n"
     ]
    }
   ],
   "source": [
    "for act in ['walking', 'eating', 'smoking', 'discussion']:\n",
    "    print(next(iter(test_data[act]))[0].shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maowei",
   "language": "python",
   "name": "maowei"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
